{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path.cwd().parent.parent.resolve()\n",
    "processed_data_path = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "all_documents_filename = processed_data_path / \"all_documents.jsonl\"\n",
    "\n",
    "with open(all_documents_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    all_documents = [json.loads(line) for line in f]\n",
    "\n",
    "print(f\"Loaded {len(all_documents)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents[2900]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = []\n",
    "for doc in all_documents:\n",
    "    chunks = text_splitter.create_documents(\n",
    "        [doc['text']],\n",
    "        metadatas=[doc['metadata']]\n",
    "    )\n",
    "    for chunk in chunks:\n",
    "        all_chunks.append(chunk)\n",
    "\n",
    "print(f\"Split {len(all_documents)} documents into {len(all_chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_chunk = all_chunks[1000]\n",
    "print(f\"Content: \\\\n{sample_chunk.page_content}\")\n",
    "print(f\"\\\\nMetadata: \\\\n{sample_chunk.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "serializable_chunks = []\n",
    "\n",
    "for chunk in all_chunks:\n",
    "    serializable_chunks.append({\n",
    "        \"page_content\": chunk.page_content,\n",
    "        \"metadata\": chunk.metadata\n",
    "    })\n",
    "\n",
    "chunks_file_path = processed_data_path / \"all_chunks.jsonl\"\n",
    "with open(chunks_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for chunk in serializable_chunks:\n",
    "        f.write(json.dumps(chunk) + \"\\n\")\n",
    "\n",
    "print(f\"Successfully saved {len(serializable_chunks)} chunks to {chunks_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "op_rag_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
